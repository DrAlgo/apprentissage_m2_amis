{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4419d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9a959f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#environnement Frozen Lake -- mettre v0 ou v1 suivant votre version\n",
    "env_fl = gym.make('FrozenLake-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d522db",
   "metadata": {},
   "source": [
    "## Environnement maison : exemple du personnage\n",
    "On reprend l'API de gym avec les méthodes reset et step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a1da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Personnage_Env:\n",
    "    \"\"\"environnement type API gym représentant l'exemple du cours\"\"\"\n",
    "    \n",
    "    def __init__(self, R):\n",
    "        \"\"\"\n",
    "        R : paramètre de récompense de l'action 1:Récolter dans l'état 1:Affamé\n",
    "        \"\"\"\n",
    "        \n",
    "        self.observation_space = gym.spaces.Discrete(3) # 0 :OK, 1 :Affamé, 2:Mort\n",
    "        self.action_space = gym.spaces.Discrete(2)      # 0 : Manger 1 : Récolter\n",
    "        self.P = {0: {0 : [(0.8, 0, 1.0, False),\n",
    "                          (0.2, 1, 1.0, False )],\n",
    "                     1 : [(0.5, 0, 10.0, False),\n",
    "                         (0.5, 1, 10.0, False)]},\n",
    "                 1 : {0: [(0.5, 0, 0.0, False),\n",
    "                         (0.25, 1, 0.0, False),\n",
    "                         (0.25, 2, 0.0, True)],\n",
    "                     1 : [(0.5, 1, R, False),\n",
    "                         (0.5, 2, R, True)]},\n",
    "                 2 : {0 : [(1.0, 2, 0.0, True)],\n",
    "                     1 : [(1.0, 2, 0.0, True)]}}\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.current_state = 0\n",
    "        return self.current_state\n",
    "        \n",
    "    def step(self, action):\n",
    "        transitions = self.P[self.current_state][action]\n",
    "        \n",
    "        #indices des actions possibles\n",
    "        choices = list(range(len(transitions)))\n",
    "        \n",
    "        # probas correspondantes\n",
    "        probas = [t[0] for t in transitions]\n",
    "        \n",
    "        #choisit i dans choices suivant la proba \n",
    "        i = np.random.choice(choices, 1, p=probas)[0]\n",
    "        \n",
    "        #mise à jour\n",
    "        self.current_state = choices[i]\n",
    "        return transitions[i][1], transitions[i][2], transitions[i][3],  None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eccac9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_p = Personnage_Env( R = 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70a38f9",
   "metadata": {},
   "source": [
    "## Evaluation de la politique aléatoire uniforme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17e7c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration_uniform_policy(env, nb_iter):\n",
    "    \"\"\"\n",
    "    iteration de valeurs sur les états pour évaluer la politique uniforme\n",
    "    \"\"\"\n",
    "    \n",
    "    states = list(range(env.observation_space.n))\n",
    "    actions = list(range(env.action_space.n))\n",
    "    nba = len(actions)\n",
    "\n",
    "    state_values = defaultdict(lambda :0.0)\n",
    "    \n",
    "    for _ in range(nb_iter):\n",
    "        for s0 in states:\n",
    "            # pour s0 état et a0 action : env.P[s0][a0] est une liste de transitions t\n",
    "            # t[0] est la proba d'aller vers un état t[1] avec un reward t[2]\n",
    "            state_values[s0] = sum([ sum([ t[0]/ nba * (t[2] + state_values[t[1]]) for t in env.P[s0][a0]])   for a0 in env.P[s0] ])\n",
    "                \n",
    "    return state_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be50a85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.value_iteration_uniform_policy.<locals>.<lambda>()>,\n",
       "            {0: 32.85714285714285, 1: 17.14285714285714, 2: 0.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_iteration_uniform_policy(env_p, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "891e9b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.value_iteration_uniform_policy.<locals>.<lambda>()>,\n",
       "            {0: 0.013939796242315783,\n",
       "             4: 0.01624866518514242,\n",
       "             1: 0.011630927299489151,\n",
       "             5: 0.0,\n",
       "             2: 0.02095298565615168,\n",
       "             6: 0.04075153684089006,\n",
       "             3: 0.010476492828075838,\n",
       "             7: 0.0,\n",
       "             8: 0.034806199313111484,\n",
       "             10: 0.14205316170740856,\n",
       "             12: 0.0,\n",
       "             9: 0.08816993275419203,\n",
       "             13: 0.17582036999624806,\n",
       "             14: 0.43929117723455224,\n",
       "             11: 0.0,\n",
       "             15: 0.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_iteration_uniform_policy(env_fl, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db527cab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
